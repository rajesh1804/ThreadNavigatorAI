import streamlit as st
from scripts.agent_graph import run_graph
from scripts.eval_samples import sample_options

# ------------------ Streamlit Page Config ------------------
st.set_page_config(page_title="ThreadNavigatorAI", layout="wide")

# ------------------ Branding Header ------------------
st.markdown("""
# ğŸ§µ ThreadNavigatorAI
**Navigate Reddit-style threads using LLM agents**
""")
# st.image("assets/banner_threadnavigatorai.png", width=600)

# ------------------ Sidebar: Product Framing ------------------
with st.sidebar:
    st.markdown("## ğŸ’¡ Why ThreadNavigatorAI?")
    st.markdown("""
Reddit-style discussions are noisy:
- ğŸ˜’ Sarcasm, trolling, off-topic replies
- ğŸ¤¯ Difficult to summarize or moderate

### âœ… This app solves that:
- ğŸ§  Smart summarization using LLM agents
- ğŸ›¡ï¸ Moderation for bias, trolling, and tone
- ğŸ’¬ Personalized reply suggestions

### âš™ï¸ Built With:
- ğŸ§  LangGraph (Agent Orchestration)
- ğŸŒ OpenRouter (LLMs like Mistral)
- ğŸ§¾ Weaviate (Semantic Memory)
- ğŸ–¥ï¸ Streamlit (Free-tier UI)
    """)
    log_level = st.checkbox("ğŸªµ Verbose Logs", value=False)
    st.markdown("---")
    st.caption("Made by [Rajesh](https://github.com/rajesh1804) | Powered by OpenRouter + LangGraph")

# ------------------ Try Demo Button ------------------
if st.button("ğŸ”¥ Try Smart Demo"):
    thread_id = "thread_002"
    query = "Summarize this thread and point out any sarcasm or trolling"
    with st.spinner("Running LangGraph agents..."):
        try:
            result = run_graph(thread_id=thread_id, user_query=query, verbose=log_level)
            latency = result.get("latency", None)

            st.success("âœ… Demo Complete!")
            st.subheader("ğŸ“ Smart Summary")
            st.markdown(result.get("summary", "_No summary returned._"))

            st.subheader("ğŸ›¡ï¸ Moderation Report")
            st.markdown(result.get("moderation_report", "_No moderation output._"))

            st.subheader("ğŸ’¬ Suggested Reply")
            st.markdown(result.get("reply_suggestion", "_No reply generated._"))

            st.subheader("â±ï¸ Latency")
            if latency is not None:
                if latency < 10:
                    st.success(f"{latency} seconds (fast âœ…)")
                elif latency < 20:
                    st.warning(f"{latency} seconds (moderate âš ï¸)")
                else:
                    st.error(f"{latency} seconds (slow âŒ)")
            else:
                st.warning("Latency not available.")

        except Exception as e:
            st.error(f"âŒ Error: {str(e)}")

st.markdown("---")

# ------------------ Tabbed Layout ------------------
tab1, tab2 = st.tabs(["ğŸ§  Agentic Workflow", "ğŸ§ª Manual Evaluation Samples"])

# ------------------ Tab 1: Agentic Workflow ------------------
with tab1:
    st.subheader("ğŸ§  Run Agentic Workflow")
    thread_id = st.selectbox("ğŸ“‚ Choose a thread", [
        "thread_001", "thread_002", "thread_003", "thread_004"])

    query = st.text_input("ğŸ’¬ Ask a question about the thread", 
                          placeholder="e.g. What's the main takeaway? Any bias?")

    if st.button("ğŸš€ Analyze Thread"):
        if thread_id and query:
            with st.spinner("Running LangGraph pipeline..."):
                try:
                    result = run_graph(thread_id=thread_id, user_query=query, verbose=log_level)
                    latency = result.get("latency", None)

                    st.success("âœ… Analysis Complete!")

                    st.markdown("### ğŸ“ Smart Summary")
                    st.markdown(result.get("summary", "_No summary returned._"))

                    st.markdown("### ğŸ›¡ï¸ Moderation Report")
                    st.markdown(result.get("moderation_report", "_No moderation output._"))

                    st.markdown("### ğŸ’¬ Suggested Reply")
                    st.markdown(result.get("reply_suggestion", "_No reply generated._"))

                    st.markdown("### â±ï¸ Latency")
                    if latency is not None:
                        if latency < 10:
                            st.success(f"{latency} seconds (fast âœ…)")
                        elif latency < 20:
                            st.warning(f"{latency} seconds (moderate âš ï¸)")
                        else:
                            st.error(f"{latency} seconds (slow âŒ)")
                    else:
                        st.warning("Latency not available.")

                except Exception as e:
                    st.error(f"âŒ Error: {str(e)}")
        else:
            st.warning("Please enter a query and select a thread.")

# ------------------ Tab 2: Manual Evaluation ------------------
with tab2:
    st.subheader("ğŸ§ª Manual Evaluation Samples")
    sample_label = st.selectbox("ğŸ§¾ Choose an evaluation case", list(sample_options.keys()))

    if st.button("ğŸ§ª Run Sample Evaluation"):
        selected_case = sample_options[sample_label]
        thread_id = selected_case["thread_id"]
        user_query = selected_case["query"]
        expected_output = selected_case["expected"]

        with st.spinner("Evaluating with agents..."):
            try:
                result = run_graph(thread_id=thread_id, user_query=user_query, verbose=log_level)
                latency = result.get("latency", None)

                st.markdown("### ğŸ“¥ Sample Input")
                st.code(f"Thread ID: {thread_id}\nQuery: {user_query}", language="text")

                st.markdown("### âœ… Model Output")
                st.markdown(result.get("summary", "_No summary returned._"))

                st.markdown("### ğŸ¯ Expected Behavior")
                st.info(expected_output)

                st.markdown("### â±ï¸ Latency")
                if latency is not None:
                    if latency < 10:
                        st.success(f"{latency} seconds (fast âœ…)")
                    elif latency < 20:
                        st.warning(f"{latency} seconds (moderate âš ï¸)")
                    else:
                        st.error(f"{latency} seconds (slow âŒ)")
                else:
                    st.warning("Latency not available.")

            except Exception as e:
                st.error(f"âŒ Error: {str(e)}")
